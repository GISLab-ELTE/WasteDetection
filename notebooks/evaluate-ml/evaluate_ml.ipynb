{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate XGBoost and RandomForest ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purpose\n",
    "\n",
    "The purpose of this notebook is to evaluate the performance of **Random Forest** and **XGBoost** models using various metrics.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for Using the Notebook\n",
    "\n",
    "To successfully use this notebook, the following paths and configurations are required:\n",
    "\n",
    "### 1. Data Files\n",
    "Ensure CSV files are prepared using the methodology described in:\n",
    "- [Creating CSV files from Planet training data](https://gitlab.inf.elte.hu/gislab/waste-detection/-/wikis/Creating-CSV-files-from-Planet-training-data)\n",
    "- Or a similar script designed for Sentinel data. (more bands)\n",
    "\n",
    "### 2. Model Checkpoints\n",
    "The models must be loaded from the specified paths:\n",
    "- **XGBoost Model Path:** `models/xgboost_model_sampled.sav`\n",
    "- **Random Forest Model Path:** `models/with_extra_unknowns.sav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Random forest and XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets `kiskore_data` and `drina_data` were created based on the methodology described in the [Waste Detection Wiki](https://gitlab.inf.elte.hu/gislab/waste-detection/-/wikis/Creating-CSV-files-from-Planet-training-data).  \n",
    "\n",
    "These CSV files (`kiskore_images.csv` and `drina_images.csv`) were generated from Planet training data and are used for testing purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiskore_data = pd.read_csv(\"test_data/kiskore_images.csv\", delimiter = \";\")\n",
    "drina_data = pd.read_csv(\"test_data/drina_images.csv\", delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If working with data from Sentinel or other sources with additional spectral bands,\n",
    "# modify the `bands` list to include the desired band names.\n",
    "\n",
    "bands = ['BLUE', 'GREEN', 'RED', 'NIR', 'PI', 'NDWI', 'NDVI', 'RNDVI', 'SR']\n",
    "\n",
    "X_kiskore = kiskore_data[bands]\n",
    "y_kiskore = kiskore_data['COD'].values\n",
    "\n",
    "X_drina= drina_data[bands]\n",
    "y_drina = drina_data['COD'].values\n",
    "\n",
    "X_merged = pd.concat([X_kiskore, X_drina], axis=0)\n",
    "\n",
    "y_merged = np.concatenate([y_kiskore, y_drina])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models (Random forest, XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model Training\n",
    "\n",
    "The XGBoost model was trained based on the methodology described in the [Waste Detection Wiki](https://gitlab.inf.elte.hu/gislab/waste-detection/-/wikis/Training-a-model).  \n",
    "\n",
    "However, the current results are suboptimal due to missing hyperparameter tuning and further adjustments. It would be more effective to train a new model with improved settings and use that for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_path = \"models/xgboost_model_sampled.sav\"\n",
    "xgboost_model = joblib.load(xgboost_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_path = 'models/with_extra_unknowns.sav'\n",
    "rf_model = joblib.load(rf_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_merged = rf_model.predict(X_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code prepares the ground truth labels and predictions from a Random Forest model\n",
    "# for binary classification. Specifically, it focuses on identifying a target class \n",
    "# (e.g., waste class label = 100) by converting multi-class labels and predictions \n",
    "# into binary format, where 1 represents the target class and 0 represents all others.\n",
    "waste_class_label = 100\n",
    "\n",
    "rf_y_pred_merged = rf_predictions_merged.astype(int)\n",
    "rf_y_true_merged = y_merged\n",
    "\n",
    "rf_y_true_bin_merged = np.where(rf_y_true_merged == waste_class_label, 1, 0)\n",
    "rf_y_pred_bin_merged = np.where(rf_y_pred_merged == waste_class_label, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_predictions_merged = xgboost_model.predict(X_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [100, 200, 300, 400, 500]\n",
    "label_mapping = {label: idx for idx, label in enumerate(class_labels)}\n",
    "inverse_label_mapping = {v: k for k, v in label_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as at RF.\n",
    "xgboost_y_pred_merged = np.array([inverse_label_mapping[label] for label in xgboost_predictions_merged])\n",
    "xgboost_y_true_merged = y_merged\n",
    "\n",
    "xgboost_y_true_bin_merged = np.where(xgboost_y_true_merged == waste_class_label, 1, 0)\n",
    "xgboost_y_pred_bin_merged = np.where(xgboost_y_pred_merged == waste_class_label, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest teljesítmény a hulladék osztályra (100):\n",
      "True Positives (TP): 4528\n",
      "False Positives (FP): 0\n",
      "True Negatives (TN): 5155\n",
      "False Negatives (FN): 13073\n",
      "Pontosság (Accuracy): 0.4255\n",
      "Precízió (Precision): 1.0000\n",
      "Visszahívás (Recall): 0.2573\n",
      "F1-score: 0.4092\n"
     ]
    }
   ],
   "source": [
    "TP_rf = np.sum((rf_y_pred_bin_merged == 1) & (rf_y_true_bin_merged == 1))\n",
    "FP_rf = np.sum((rf_y_pred_bin_merged == 1) & (rf_y_true_bin_merged == 0))\n",
    "TN_rf = np.sum((rf_y_pred_bin_merged == 0) & (rf_y_true_bin_merged == 0))\n",
    "FN_rf = np.sum((rf_y_pred_bin_merged == 0) & (rf_y_true_bin_merged == 1))\n",
    "\n",
    "accuracy_rf = (TP_rf + TN_rf) / (TP_rf + TN_rf + FP_rf + FN_rf)\n",
    "precision_rf = TP_rf / (TP_rf + FP_rf) if (TP_rf + FP_rf) > 0 else 0\n",
    "recall_rf = TP_rf / (TP_rf + FN_rf) if (TP_rf + FN_rf) > 0 else 0\n",
    "f1_score_rf = 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf) if (precision_rf + recall_rf) > 0 else 0\n",
    "\n",
    "print(f\"\\nRandom Forest teljesítmény a hulladék osztályra ({waste_class_label}):\")\n",
    "print(f\"True Positives (TP): {TP_rf}\")\n",
    "print(f\"False Positives (FP): {FP_rf}\")\n",
    "print(f\"True Negatives (TN): {TN_rf}\")\n",
    "print(f\"False Negatives (FN): {FN_rf}\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1-score: {f1_score_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost teljesítmény a hulladék osztályra (100):\n",
      "True Positives (TP): 293\n",
      "False Positives (FP): 0\n",
      "True Negatives (TN): 5155\n",
      "False Negatives (FN): 17308\n",
      "Pontosság (Accuracy): 0.2394\n",
      "Precízió (Precision): 1.0000\n",
      "Visszahívás (Recall): 0.0166\n",
      "F1-score: 0.0327\n"
     ]
    }
   ],
   "source": [
    "TP_xgboost = np.sum((xgboost_y_pred_bin_merged == 1) & (xgboost_y_true_bin_merged == 1))\n",
    "FP_xgboost = np.sum((xgboost_y_pred_bin_merged == 1) & (xgboost_y_true_bin_merged == 0))\n",
    "TN_xgboost = np.sum((xgboost_y_pred_bin_merged == 0) & (xgboost_y_true_bin_merged == 0))\n",
    "FN_xgboost = np.sum((xgboost_y_pred_bin_merged == 0) & (xgboost_y_true_bin_merged == 1))\n",
    "\n",
    "accuracy_xgb = (TP_xgboost + TN_xgboost) / (TP_xgboost + TN_xgboost + FP_xgboost + FN_xgboost)\n",
    "precision_xgb = TP_xgboost / (TP_xgboost + FP_xgboost) if (TP_xgboost + FP_xgboost) > 0 else 0\n",
    "recall_xgb = TP_xgboost / (TP_xgboost + FN_xgboost) if (TP_xgboost + FN_xgboost) > 0 else 0\n",
    "f1_score_xgb = 2 * (precision_xgb * recall_xgb) / (precision_xgb + recall_xgb) if (precision_xgb + recall_xgb) > 0 else 0\n",
    "\n",
    "print(f\"\\nXGBoost teljesítmény a hulladék osztályra ({waste_class_label}):\")\n",
    "print(f\"True Positives (TP): {TP_xgboost}\")\n",
    "print(f\"False Positives (FP): {FP_xgboost}\")\n",
    "print(f\"True Negatives (TN): {TN_xgboost}\")\n",
    "print(f\"False Negatives (FN): {FN_xgboost}\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"Precision: {precision_xgb:.4f}\")\n",
    "print(f\"Recall: {recall_xgb:.4f}\")\n",
    "print(f\"F1-score: {f1_score_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_xgb = {\n",
    "    'True Positives (TP)': TP_xgboost,\n",
    "    'False Positives (FP)': FP_xgboost,\n",
    "    'True Negatives (TN)': TN_xgboost,\n",
    "    'False Negatives (FN)': FN_xgboost,\n",
    "    'Accuracy': accuracy_xgb,\n",
    "    'Precision': precision_xgb,\n",
    "    'Recall': recall_xgb,\n",
    "    'F1-score': f1_score_xgb,\n",
    "}\n",
    "\n",
    "metrics_rf = {\n",
    "    'True Positives (TP)': TP_rf,\n",
    "    'False Positives (FP)': FP_rf,\n",
    "    'True Negatives (TN)': TN_rf,\n",
    "    'False Negatives (FN)': FN_rf,\n",
    "    'Accuracy': accuracy_rf,\n",
    "    'Precision': precision_rf,\n",
    "    'Recall': recall_rf,\n",
    "    'F1-score': f1_score_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "results = {\n",
    "    'XGBoost': metrics_xgb,\n",
    "    'Random Forest': metrics_rf,\n",
    "}\n",
    "\n",
    "with open('model_metrics_ml.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4, default=convert_numpy_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WasteDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
