{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate UNet and UNetPP CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purpose\n",
    "\n",
    "The purpose of this notebook is to test **U-Net** and **U-Net++** models based on various metrics.  \n",
    "\n",
    "To keep the notebook clean and focused, a separate `load_unets` file is included, which handles the loading of the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for Using the Notebook\n",
    "\n",
    "To successfully use this notebook, the following paths and configurations are required:\n",
    "\n",
    "### 1. Model Checkpoint Paths\n",
    "Ensure the U-Net and U-Net++ model checkpoints are available at the specified paths:\n",
    "- **U-Net Checkpoint:** `models/200.sav`\n",
    "- **U-Net++ Checkpoint:** `models/dice_unetpp.sav`\n",
    "\n",
    "### 2. Data Directories\n",
    "The dataset should be organized as follows:\n",
    "- **Image Directory:** `test_data/images`\n",
    "- **Label Directory:** `test_data/labels`\n",
    "\n",
    "### 3. Label File Naming Convention\n",
    "The label files must follow a specific naming pattern to be correctly matched with the image files. In the dataset loader, the label path is constructed as:\n",
    "```python\n",
    "label_path = os.path.join(self.label_dir, file.replace('clip_reproject', 'clip_reproject_classified'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from osgeo import gdal\n",
    "import skimage as sk\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import rasterio\n",
    "from torchvision import transforms\n",
    "import json\n",
    "from load_unets import load_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for UNet and UNetPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomSatelliteDataset\n",
    "\n",
    "This class is based on an implementation originally created by **ZoltÃ¡n Gugolya**,  \n",
    "simplified and adapted for testing purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSatelliteDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith('.tif')]\n",
    "        self.images, self.labels = self.load_tif_images_and_labels()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        image = image.permute(1, 0, 2)\n",
    "        \n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def load_tif_images_and_labels(self):\n",
    "        tif_images = []\n",
    "        tif_labels = []\n",
    "\n",
    "        for file in self.image_filenames:\n",
    "            image_path = os.path.join(self.image_dir, file)\n",
    "            label_path = os.path.join(self.label_dir, file.replace('clip_reproject', 'clip_reproject_classified'))\n",
    "\n",
    "            try:\n",
    "                ds = gdal.Open(image_path, gdal.GA_ReadOnly)\n",
    "                rows = ds.RasterYSize\n",
    "                cols = ds.RasterXSize\n",
    "                bands = ds.RasterCount\n",
    "                array = ds.ReadAsArray().astype(dtype=\"float32\")\n",
    "\n",
    "                if array.shape != (bands, rows, cols):\n",
    "                    array = np.reshape(array, [bands, rows, cols])\n",
    "\n",
    "                max_value = array.max(axis=(1, 2), keepdims=True)\n",
    "                array = array / max_value\n",
    "\n",
    "                with rasterio.open(label_path) as label_img:\n",
    "                    label_array = label_img.read(1).astype('f4')\n",
    "\n",
    "                labeled_img = sk.measure.label(label_array)\n",
    "                regions = sk.measure.regionprops(labeled_img)\n",
    "\n",
    "                for props in regions:\n",
    "                    minr, minc, maxr, maxc = props.bbox\n",
    "                    center = np.array([(minr + maxr) // 2, (minc + maxc) // 2])\n",
    "                    start_x = max(center[0] - 64, 0)\n",
    "                    start_y = max(center[1] - 64, 0)\n",
    "                    end_x = min(start_x + 128, array.shape[1])\n",
    "                    end_y = min(start_y + 128, array.shape[2])\n",
    "\n",
    "                    cut = array[:, start_x:end_x, start_y:end_y]\n",
    "                    cut_label = label_array[start_x:end_x, start_y:end_y]\n",
    "\n",
    "                    if cut.shape[1:] != (128, 128):\n",
    "                        cut = self.pad_to_shape(cut, (128, 128))\n",
    "                        cut_label = self.pad_to_shape(cut_label, (128, 128))\n",
    "\n",
    "                    tif_images.append(cut)\n",
    "                    tif_labels.append(cut_label)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while loading {image_path} or {label_path}: {e}\")\n",
    "        \n",
    "        return np.stack(tif_images, axis=0), np.stack(tif_labels, axis=0)\n",
    "\n",
    "    def pad_to_shape(self, array, target_shape):\n",
    "        if len(array.shape) == 2:\n",
    "            padding = [(max(target_shape[i] - array.shape[i], 0) // 2,\n",
    "                        max(target_shape[i] - array.shape[i], 0) - max(target_shape[i] - array.shape[i], 0) // 2)\n",
    "                       for i in range(2)]\n",
    "        elif len(array.shape) == 3:\n",
    "            padding = [(0, 0)] + [(max(target_shape[i] - array.shape[i + 1], 0) // 2,\n",
    "                                   max(target_shape[i] - array.shape[i + 1], 0) - max(target_shape[i] - array.shape[i + 1], 0) // 2)\n",
    "                                  for i in range(2)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input shape for padding\")\n",
    "\n",
    "        return np.pad(array, padding, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "image_dir_merged = 'test_data/images'\n",
    "label_dir_merged = 'test_data/labels'\n",
    "\n",
    "test_dataset_merged = CustomSatelliteDataset(image_dir_merged, label_dir_merged, transform=transform)\n",
    "\n",
    "test_merged_loader = DataLoader(test_dataset_merged, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset_merged))\n",
    "\n",
    "for images, labels in test_merged_loader:\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models (UNet, UNetPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_checkpoint_path = 'models/200.sav'\n",
    "unetpp_checkpoint_path = 'models/dice_unetpp.sav'\n",
    "\n",
    "model_unet, model_unetpp = load_models(unet_checkpoint_path, unetpp_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ground_truths_merged = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_unet_merged = []\n",
    "\n",
    "model_unet.to(device)\n",
    "model_unet.eval()\n",
    "\n",
    "for inputs, labels in test_merged_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs_unet = model_unet.predict(inputs)\n",
    "        preds_unet = (outputs_unet > 0.5).float()\n",
    "    predictions_unet_merged.append(preds_unet.cpu())\n",
    "    ground_truths_merged.append(labels.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNetPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamil\\AppData\\Local\\Temp\\ipykernel_16688\\2176729264.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(image, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "predictions_unetpp_merged = []\n",
    "\n",
    "model_unetpp.to(device)\n",
    "model_unetpp.eval()\n",
    "\n",
    "for inputs, labels in test_merged_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs_unetpp = model_unetpp.predict(inputs)\n",
    "        preds_unetpp = (outputs_unetpp > 0.5).float()\n",
    "    predictions_unetpp_merged.append(preds_unetpp.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predictions and ground truths into a single tensor along dimension 0.\n",
    "# This is necessary when predictions and ground truths are collected in batches during evaluation\n",
    "# and need to be combined into one tensor for overall metric computation.\n",
    "predictions_unet_merged = torch.cat(predictions_unet_merged, dim=0)\n",
    "predictions_unetpp_merged = torch.cat(predictions_unetpp_merged, dim=0)\n",
    "ground_truths_merged = torch.cat(ground_truths_merged, dim=0)\n",
    "\n",
    "# Flatten the merged tensors to convert them into a 1D format.\n",
    "# This step is required for computing metrics like accuracy, precision, recall, or F1-score,\n",
    "# which typically operate on flat arrays of predictions and labels.\n",
    "preds_unet_flat_merged = predictions_unet_merged.view(-1)\n",
    "preds_unetpp_flat_merged = predictions_unetpp_merged.view(-1)\n",
    "labels_flat_merged = ground_truths_merged.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in preds_unet_flat: tensor([0., 1.])\n",
      "Unique values in labels_flat: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "binary_labels_merged = torch.where(labels_flat_merged == 100, 1, 0)\n",
    "print(\"Unique values in preds_unet_flat:\", preds_unet_flat_merged.unique())\n",
    "print(\"Unique values in labels_flat:\", binary_labels_merged.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([475136]) torch.Size([475136])\n"
     ]
    }
   ],
   "source": [
    "TP_unet = ((preds_unet_flat_merged == 1) & (binary_labels_merged == 1)).sum().item()\n",
    "TN_unet = ((preds_unet_flat_merged == 0) & (binary_labels_merged == 0)).sum().item()\n",
    "FP_unet = ((preds_unet_flat_merged == 1) & (binary_labels_merged == 0)).sum().item()\n",
    "FN_unet = ((preds_unet_flat_merged == 0) & (binary_labels_merged == 1)).sum().item()\n",
    "\n",
    "# Accuary\n",
    "accuracy_unet = (TP_unet + TN_unet) / (TP_unet + TN_unet + FP_unet + FN_unet)\n",
    "# Precision\n",
    "precision_unet = TP_unet / (TP_unet + FP_unet) if (TP_unet + FP_unet) > 0 else 0\n",
    "# Recall\n",
    "recall_unet = TP_unet / (TP_unet + FN_unet) if (TP_unet + FN_unet) > 0 else 0\n",
    "# F1-score\n",
    "f1_score_unet = 2 * (precision_unet * recall_unet) / (precision_unet + recall_unet) if (precision_unet + recall_unet) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UnetPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_unetpp = ((preds_unetpp_flat_merged == 1) & (binary_labels_merged == 1)).sum().item()\n",
    "TN_unetpp = ((preds_unetpp_flat_merged == 0) & (binary_labels_merged == 0)).sum().item()\n",
    "FP_unetpp = ((preds_unetpp_flat_merged == 1) & (binary_labels_merged == 0)).sum().item()\n",
    "FN_unetpp = ((preds_unetpp_flat_merged == 0) & (binary_labels_merged == 1)).sum().item()\n",
    "\n",
    "# Accuracy\n",
    "accuracy_unetpp = (TP_unetpp + TN_unetpp) / (TP_unetpp + TN_unetpp + FP_unetpp + FN_unetpp)\n",
    "# Precision\n",
    "precision_unetpp = TP_unetpp / (TP_unetpp + FP_unetpp) if (TP_unetpp + FP_unetpp) > 0 else 0\n",
    "# VRecall\n",
    "recall_unetpp = TP_unetpp / (TP_unetpp + FN_unetpp) if (TP_unetpp + FN_unetpp) > 0 else 0\n",
    "# F1-score\n",
    "f1_score_unetpp = 2 * (precision_unetpp * recall_unetpp) / (precision_unetpp + recall_unetpp) if (precision_unetpp + recall_unetpp) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_unet = {\n",
    "    'True Positives (TP)': TP_unet,\n",
    "    'False Positives (FP)': FP_unet,\n",
    "    'True Negatives (TN)': TN_unet,\n",
    "    'False Negatives (FN)': FN_unet,\n",
    "    'Accuracy': accuracy_unet,\n",
    "    'Precision': precision_unet,\n",
    "    'Recall': recall_unet,\n",
    "    'F1-score': f1_score_unet\n",
    "}\n",
    "\n",
    "\n",
    "metrics_unetpp = {\n",
    "    'True Positives (TP)': TP_unetpp,\n",
    "    'False Positives (FP)': FP_unetpp,\n",
    "    'True Negatives (TN)': TN_unetpp,\n",
    "    'False Negatives (FN)': FN_unetpp,\n",
    "    'Accuracy': accuracy_unetpp,\n",
    "    'Precision': precision_unetpp,\n",
    "    'Recall': recall_unetpp,\n",
    "    'F1-score': f1_score_unetpp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "results = {\n",
    "    'UNet': metrics_unet,\n",
    "    'UNet++': metrics_unetpp\n",
    "}\n",
    "\n",
    "with open('model_metrics_unets.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4, default=convert_numpy_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WasteDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
